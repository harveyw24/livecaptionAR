{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fairseq\n",
    "from avhubert import hubert_pretraining, hubert\n",
    "from avhubert import extract_roi\n",
    "\n",
    "import cv2\n",
    "import tempfile\n",
    "from argparse import Namespace\n",
    "import fairseq\n",
    "import sys\n",
    "import pickle\n",
    "import joblib\n",
    "from fairseq import checkpoint_utils, options, tasks, utils\n",
    "from fairseq.dataclass.configs import GenerationConfig\n",
    "import torch\n",
    "import os\n",
    "from os.path import exists\n",
    "import subprocess\n",
    "from avhubert import extract_roi\n",
    "import extract_mouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newPredict(video_path, audio_path, user_dir, models, cfg, task):\n",
    "  num_frames = int(cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "  data_dir = tempfile.mkdtemp()\n",
    "  tsv_cont = [\"/\\n\", f\"test-0\\t{video_path}\\t{audio_path}\\t{num_frames}\\t{int(16_000*num_frames/25)}\\n\"]\n",
    "  label_cont = [\"DUMMY\\n\"]\n",
    "  with open(f\"{data_dir}/test.tsv\", \"w\") as fo:\n",
    "    fo.write(\"\".join(tsv_cont))\n",
    "  with open(f\"{data_dir}/test.wrd\", \"w\") as fo:\n",
    "    fo.write(\"\".join(label_cont))\n",
    "  utils.import_user_module(Namespace(user_dir=user_dir))\n",
    "  modalities = [\"audio\", \"video\"]\n",
    "  gen_subset = \"test\"\n",
    "  gen_cfg = GenerationConfig(beam=20)\n",
    "  cfg.task.modalities = modalities\n",
    "  cfg.task.data = data_dir\n",
    "  cfg.task.label_dir = data_dir\n",
    "  cfg.task.max_sample_size = 1000\n",
    "  task = tasks.setup_task(cfg.task)\n",
    "  task.cfg.noise_wav = None # TODO: edit\n",
    "  task.cfg.noise_prob = 0 # TODO: edit\n",
    "  task.load_dataset(gen_subset, task_cfg=cfg.task)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    mods = []\n",
    "    for model in models:\n",
    "      mods.append(model.cuda().eval())\n",
    "      # model.cpu()\n",
    "      torch.cuda.empty_cache()\n",
    "  models = mods\n",
    "  print(models)\n",
    "\n",
    "  # models = [model.eval().cuda() for model in models]\n",
    "\n",
    "  generator = task.build_generator(models, gen_cfg)\n",
    "\n",
    "  def decode_fn(x):\n",
    "      dictionary = task.target_dictionary\n",
    "      symbols_ignore = generator.symbols_to_strip_from_output\n",
    "      symbols_ignore.add(dictionary.pad())\n",
    "      return task.datasets[gen_subset].label_processors[0].decode(x, symbols_ignore)\n",
    "\n",
    "  itr = task.get_batch_iterator(dataset=task.dataset(gen_subset)).next_epoch_itr(shuffle=False)\n",
    "  sample = next(itr)\n",
    "  sample = utils.move_to_cuda(sample)\n",
    "  hypos = task.inference_step(generator, models, sample)\n",
    "  ref = decode_fn(sample['target'][0].int().cpu())\n",
    "  hypo = hypos[0][0]['tokens'].int().cpu()\n",
    "  hypo = decode_fn(hypo)\n",
    "  return hypo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd =os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# def load_model(wd, ckpt_path):\n",
    "#     if not (exists(f'{wd}/data/model/models.pkl') and exists(f'{wd}/data/model/cfg.pkl') and exists(f'{wd}/data/model/task.pkl')):\n",
    "#         models, cfg, task = fairseq.checkpoint_utils.load_model_ensemble_and_task([ckpt_path])\n",
    "#         with open(f'{wd}/data/model/models.pkl', 'wb') as file:\n",
    "#             pickle.dump(models, file)\n",
    "#         with open(f'{wd}/data/model/cfg.pkl', 'wb') as file:\n",
    "#             pickle.dump(cfg, file)\n",
    "#         with open(f'{wd}/task.pkl', 'wb') as file:\n",
    "#             pickle.dump(task, file)\n",
    "#     else:\n",
    "#         with open('models.pkl', 'rb') as file:\n",
    "#             models = pickle.load(file)\n",
    "#         with open('cfg.pkl', 'rb') as file:\n",
    "#             cfg = pickle.load(file)\n",
    "#         with open('task.pkl', 'rb') as file:\n",
    "#             task = pickle.load(file)\n",
    "\n",
    "#     return models, cfg, task\n",
    "\n",
    "\n",
    "ckpt_path = f\"{wd}/data/misc/large_noise_pt_noise_ft_433h.pt\"\n",
    "# models, cfg, task = load_model(wd, ckpt_path)\n",
    "models, cfg, task = fairseq.checkpoint_utils.load_model_ensemble_and_task([ckpt_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = f\"{wd}/data/misc/large_noise_pt_noise_ft_433h.pt\"\n",
    "models, cfg, task = fairseq.checkpoint_utils.load_model_ensemble_and_task([ckpt_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/harveyw/harveyw/iw/av_hubert_updated/av_hubert/av_hubert\n"
     ]
    }
   ],
   "source": [
    "print(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"angel_clip.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 278/278 [00:56<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         185755 function calls (181877 primitive calls) in 64.313 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      557    0.001    0.000    0.013    0.000 <__array_function__ internals>:2(all)\n",
      "      278    0.000    0.000    0.007    0.000 <__array_function__ internals>:2(around)\n",
      "      278    0.000    0.000    0.006    0.000 <__array_function__ internals>:2(atleast_2d)\n",
      "      278    0.001    0.000    0.007    0.000 <__array_function__ internals>:2(atleast_3d)\n",
      "      278    0.001    0.000    0.101    0.000 <__array_function__ internals>:2(clip)\n",
      "      556    0.002    0.000    0.103    0.000 <__array_function__ internals>:2(concatenate)\n",
      "      278    0.001    0.000    0.005    0.000 <__array_function__ internals>:2(copy)\n",
      "      545    0.001    0.000    0.004    0.000 <__array_function__ internals>:2(copyto)\n",
      "      267    0.001    0.000    0.011    0.000 <__array_function__ internals>:2(count_nonzero)\n",
      "      267    0.001    0.000    0.013    0.000 <__array_function__ internals>:2(det)\n",
      "      267    0.000    0.000    0.004    0.000 <__array_function__ internals>:2(diag)\n",
      "      278    0.001    0.000    0.112    0.000 <__array_function__ internals>:2(dstack)\n",
      "      278    0.001    0.000    0.002    0.000 <__array_function__ internals>:2(empty_like)\n",
      "      278    0.001    0.000    0.016    0.000 <__array_function__ internals>:2(inv)\n",
      "      278    0.001    0.000    0.036    0.000 <__array_function__ internals>:2(isclose)\n",
      "      267    0.000    0.000    0.036    0.000 <__array_function__ internals>:2(matrix_rank)\n",
      "      545    0.002    0.000    0.048    0.000 <__array_function__ internals>:2(mean)\n",
      "      556    0.001    0.000    0.003    0.000 <__array_function__ internals>:2(ndim)\n",
      "      278    0.001    0.000    0.007    0.000 <__array_function__ internals>:2(ones_like)\n",
      "      278    0.001    0.000    0.001    0.000 <__array_function__ internals>:2(result_type)\n",
      "      278    0.001    0.000    0.009    0.000 <__array_function__ internals>:2(round_)\n",
      "      534    0.001    0.000    0.029    0.000 <__array_function__ internals>:2(svd)\n",
      "      278    0.001    0.000    0.003    0.000 <__array_function__ internals>:2(transpose)\n",
      "      278    0.001    0.000    0.013    0.000 <__array_function__ internals>:2(vstack)\n",
      "      278    0.002    0.000    0.004    0.000 <frozen importlib._bootstrap>:1017(_handle_fromlist)\n",
      "        1    0.030    0.030   64.313   64.313 <string>:1(<module>)\n",
      "       20    0.000    0.000    0.000    0.000 <string>:1(__new__)\n",
      "        1    0.000    0.000    0.129    0.129 __init__.py:201(check_output)\n",
      "       10    0.000    0.000    0.000    0.000 __init__.py:266(__getattr__)\n",
      "     4927    0.003    0.000    0.016    0.000 _asarray.py:110(asanyarray)\n",
      "     1668    0.003    0.000    0.761    0.000 _asarray.py:183(ascontiguousarray)\n",
      "     3292    0.004    0.000    0.017    0.000 _asarray.py:23(asarray)\n",
      "        1    0.000    0.000    0.000    0.000 _bootlocale.py:33(getpreferredencoding)\n",
      "        1    0.000    0.000    0.000    0.000 _collections_abc.py:657(get)\n",
      "      267    0.002    0.000    0.007    0.000 _geometric.py:1119(__init__)\n",
      "     1068    0.000    0.000    0.000    0.000 _geometric.py:1121(<genexpr>)\n",
      "      267    0.001    0.000    0.147    0.001 _geometric.py:1150(estimate)\n",
      "      267    0.002    0.000    0.157    0.001 _geometric.py:1342(estimate_transform)\n",
      "      278    0.027    0.000    0.052    0.000 _geometric.py:548(_apply_mat)\n",
      "      278    0.001    0.000    0.053    0.000 _geometric.py:564(__call__)\n",
      "      267    0.028    0.000    0.146    0.001 _geometric.py:72(_umeyama)\n",
      "      556    0.001    0.000    0.002    0.000 _methods.py:100(_clip_dep_is_byte_swapped)\n",
      "      278    0.079    0.000    0.079    0.000 _methods.py:105(_clip_dep_invoke_with_casting)\n",
      "      278    0.002    0.000    0.093    0.000 _methods.py:124(_clip)\n",
      "     1079    0.020    0.000    0.055    0.000 _methods.py:161(_mean)\n",
      "      267    0.012    0.000    0.020    0.000 _methods.py:194(_var)\n",
      "      545    0.001    0.000    0.248    0.000 _methods.py:37(_amax)\n",
      "      278    0.001    0.000    0.250    0.001 _methods.py:41(_amin)\n",
      "      534    0.000    0.000    0.005    0.000 _methods.py:45(_sum)\n",
      "     1390    0.001    0.000    0.009    0.000 _methods.py:59(_all)\n",
      "     1346    0.009    0.000    0.011    0.000 _methods.py:65(_count_reduce_items)\n",
      "      556    0.008    0.000    0.011    0.000 _methods.py:90(_clip_dep_is_scalar_nan)\n",
      "        1    0.000    0.000    0.001    0.001 _monitor.py:32(__init__)\n",
      "        1    0.000    0.000    0.001    0.001 _monitor.py:50(exit)\n",
      "        1    0.000    0.000    0.000    0.000 _monitor.py:98(report)\n",
      "      556    0.002    0.000    0.002    0.000 _ufunc_config.py:132(geterr)\n",
      "      556    0.002    0.000    0.006    0.000 _ufunc_config.py:32(seterr)\n",
      "      278    0.000    0.000    0.000    0.000 _ufunc_config.py:429(__init__)\n",
      "      278    0.001    0.000    0.005    0.000 _ufunc_config.py:433(__enter__)\n",
      "      278    0.001    0.000    0.003    0.000 _ufunc_config.py:438(__exit__)\n",
      "      278    0.004    0.000    0.601    0.002 _warps.py:638(_clip_warp_output)\n",
      "      278    1.922    0.007    3.990    0.014 _warps.py:684(warp)\n",
      "        1    0.000    0.000    0.000    0.000 _weakrefset.py:106(remove)\n",
      "        2    0.000    0.000    0.000    0.000 _weakrefset.py:16(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 _weakrefset.py:20(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 _weakrefset.py:26(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 _weakrefset.py:52(_commit_removals)\n",
      "        3    0.000    0.000    0.000    0.000 _weakrefset.py:58(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 _weakrefset.py:67(__len__)\n",
      "        2    0.000    0.000    0.000    0.000 _weakrefset.py:81(add)\n",
      "        4    0.000    0.000    0.000    0.000 abc.py:96(__instancecheck__)\n",
      "        2    0.000    0.000    0.000    0.000 abstract.py:223(_dict2Args)\n",
      "        1    0.000    0.000    0.000    0.000 abstract.py:230(getShape)\n",
      "        1    0.000    0.000    0.011    0.011 abstract.py:238(close)\n",
      "        1    0.000    0.000    0.011    0.011 abstract.py:246(_terminate)\n",
      "        1    0.000    0.000    0.184    0.184 abstract.py:25(__init__)\n",
      "      278    0.004    0.000    0.518    0.002 abstract.py:263(_read_frame_data)\n",
      "      278    0.002    0.000    0.521    0.002 abstract.py:280(_readFrame)\n",
      "      279    0.001    0.000    0.522    0.002 abstract.py:300(nextFrame)\n",
      "        1    0.015    0.015    4.601    4.601 align_mouth.py:131(crop_patch)\n",
      "        1    0.000    0.000    0.000    0.000 align_mouth.py:185(landmarks_interpolate)\n",
      "        1    0.000    0.000    0.000    0.000 align_mouth.py:191(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 align_mouth.py:199(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 align_mouth.py:204(<listcomp>)\n",
      "      267    0.058    0.000    4.099    0.015 align_mouth.py:33(warp_img)\n",
      "       11    0.002    0.000    0.148    0.013 align_mouth.py:40(apply_transform)\n",
      "        1    0.004    0.004    0.006    0.006 align_mouth.py:46(get_frame_count)\n",
      "      279    0.005    0.000    0.212    0.001 align_mouth.py:52(read_video)\n",
      "      278    0.008    0.000    0.035    0.000 align_mouth.py:63(cut_patch)\n",
      "        1    0.002    0.002    0.559    0.559 align_mouth.py:89(write_video_ffmpeg)\n",
      "        1    0.000    0.000    0.000    0.000 ast.py:30(parse)\n",
      "        1    0.000    0.000    0.000    0.000 ast.py:51(literal_eval)\n",
      "      9/1    0.000    0.000    0.000    0.000 ast.py:76(_convert)\n",
      "        1    0.000    0.000    0.000    0.000 codecs.py:186(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 contextlib.py:375(_create_exit_wrapper)\n",
      "        6    0.000    0.000    0.000    0.000 contextlib.py:379(_create_cb_wrapper)\n",
      "        6    0.000    0.000    0.000    0.000 contextlib.py:381(_exit_wrapper)\n",
      "        4    0.000    0.000    0.000    0.000 contextlib.py:385(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 contextlib.py:415(enter_context)\n",
      "        6    0.000    0.000    0.000    0.000 contextlib.py:429(callback)\n",
      "        1    0.000    0.000    0.000    0.000 contextlib.py:458(_push_cm_exit)\n",
      "        7    0.000    0.000    0.000    0.000 contextlib.py:463(_push_exit_callback)\n",
      "        4    0.000    0.000    0.000    0.000 contextlib.py:479(__enter__)\n",
      "        4    0.000    0.000    0.000    0.000 contextlib.py:482(__exit__)\n",
      "      278    0.448    0.002    0.457    0.002 dtype.py:179(_convert)\n",
      "      278    0.001    0.000    0.458    0.002 dtype.py:432(img_as_float)\n",
      "      278    0.001    0.000    0.002    0.000 dtype.py:60(_dtype_itemsize)\n",
      "      556    0.001    0.000    0.001    0.000 dtype.py:80(<genexpr>)\n",
      "       19    0.000    0.000    0.000    0.000 enum.py:753(value)\n",
      "      278   56.374    0.203   56.627    0.204 extract_roi.py:44(detect_landmark)\n",
      "        1    0.788    0.788   64.283   64.283 extract_roi.py:55(preprocess_video)\n",
      "        1    0.001    0.001    0.001    0.001 extract_roi.py:62(<listcomp>)\n",
      "        1    0.000    0.000    0.184    0.184 ffmpeg.py:42(__init__)\n",
      "        1    0.000    0.000    0.054    0.054 ffmpeg.py:46(_createProcess)\n",
      "        1    0.000    0.000    0.129    0.129 ffmpeg.py:73(_probe)\n",
      "        1    0.000    0.000    0.000    0.000 ffmpeg.py:76(_getSupportedDecoders)\n",
      "        1    0.000    0.000    0.129    0.129 ffprobe.py:8(ffprobe)\n",
      "        1    0.000    0.000    0.000    0.000 format.py:190(_check_version)\n",
      "        1    0.000    0.000    0.000    0.000 format.py:217(read_magic)\n",
      "        1    0.000    0.000    0.000    0.000 format.py:282(descr_to_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 format.py:535(_filter_header)\n",
      "        1    0.000    0.000    0.001    0.001 format.py:570(_read_array_header)\n",
      "        1    0.000    0.000    0.000    0.000 format.py:609(<listcomp>)\n",
      "        1    0.000    0.000    0.001    0.001 format.py:695(read_array)\n",
      "        3    0.000    0.000    0.000    0.000 format.py:889(_read_bytes)\n",
      "      278    0.000    0.000    0.000    0.000 fromnumeric.py:2040(_clip_dispatcher)\n",
      "      278    0.002    0.000    0.097    0.000 fromnumeric.py:2044(clip)\n",
      "      557    0.000    0.000    0.000    0.000 fromnumeric.py:2350(_all_dispatcher)\n",
      "      557    0.002    0.000    0.010    0.000 fromnumeric.py:2355(all)\n",
      "      556    0.000    0.000    0.000    0.000 fromnumeric.py:3102(_ndim_dispatcher)\n",
      "      556    0.000    0.000    0.000    0.000 fromnumeric.py:3106(ndim)\n",
      "      556    0.000    0.000    0.000    0.000 fromnumeric.py:3195(_around_dispatcher)\n",
      "      278    0.000    0.000    0.006    0.000 fromnumeric.py:3199(around)\n",
      "      545    0.000    0.000    0.000    0.000 fromnumeric.py:3296(_mean_dispatcher)\n",
      "      545    0.005    0.000    0.043    0.000 fromnumeric.py:3301(mean)\n",
      "      278    0.001    0.000    0.007    0.000 fromnumeric.py:3709(round_)\n",
      "      278    0.002    0.000    0.004    0.000 fromnumeric.py:39(_wrapit)\n",
      "      834    0.002    0.000    0.102    0.000 fromnumeric.py:52(_wrapfunc)\n",
      "      278    0.000    0.000    0.000    0.000 fromnumeric.py:598(_transpose_dispatcher)\n",
      "      278    0.000    0.000    0.002    0.000 fromnumeric.py:602(transpose)\n",
      "      557    0.003    0.000    0.009    0.000 fromnumeric.py:70(_wrapreduction)\n",
      "      557    0.001    0.000    0.001    0.000 fromnumeric.py:71(<dictcomp>)\n",
      "      278    0.000    0.000    0.000    0.000 function_base.py:711(_copy_dispatcher)\n",
      "      278    0.000    0.000    0.003    0.000 function_base.py:715(copy)\n",
      "        1    0.000    0.000    0.000    0.000 genericpath.py:121(_splitext)\n",
      "        1    0.000    0.000    0.000    0.000 genericpath.py:16(exists)\n",
      "        2    0.000    0.000    0.000    0.000 genericpath.py:27(isfile)\n",
      "        1    0.000    0.000    0.000    0.000 genericpath.py:39(isdir)\n",
      "        1    0.000    0.000    0.000    0.000 genericpath.py:48(getsize)\n",
      "        1    0.000    0.000    0.000    0.000 genericpath.py:87(samestat)\n",
      "      545    0.002    0.000    0.002    0.000 getlimits.py:382(__new__)\n",
      "      556    0.002    0.000    0.002    0.000 getlimits.py:514(__init__)\n",
      "      278    0.000    0.000    0.000    0.000 getlimits.py:525(min)\n",
      "      278    0.001    0.000    0.001    0.000 getlimits.py:538(max)\n",
      "        1    0.120    0.120    0.837    0.837 io.py:77(vread)\n",
      "      841    0.004    0.000    0.047    0.000 iostream.py:202(schedule)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:304(fileno)\n",
      "      282    0.001    0.000    0.002    0.000 iostream.py:429(_is_master_process)\n",
      "      282    0.001    0.000    0.027    0.000 iostream.py:448(_schedule_flush)\n",
      "      280    0.003    0.000    0.211    0.001 iostream.py:463(flush)\n",
      "      282    0.003    0.000    0.033    0.000 iostream.py:518(write)\n",
      "      841    0.001    0.000    0.001    0.000 iostream.py:90(_event_pipe)\n",
      "      812    0.001    0.000    0.001    0.000 linalg.py:102(get_linalg_error_extobj)\n",
      "      812    0.001    0.000    0.003    0.000 linalg.py:107(_makearray)\n",
      "     2158    0.001    0.000    0.001    0.000 linalg.py:112(isComplexType)\n",
      "     1613    0.001    0.000    0.002    0.000 linalg.py:125(_realType)\n",
      "     1079    0.003    0.000    0.006    0.000 linalg.py:135(_commonType)\n",
      "      534    0.000    0.000    0.000    0.000 linalg.py:1478(_svd_dispatcher)\n",
      "      534    0.019    0.000    0.027    0.000 linalg.py:1482(svd)\n",
      "      267    0.000    0.000    0.000    0.000 linalg.py:1800(_matrix_rank_dispatcher)\n",
      "      267    0.008    0.000    0.035    0.000 linalg.py:1804(matrix_rank)\n",
      "     1079    0.001    0.000    0.001    0.000 linalg.py:193(_assert_stacked_2d)\n",
      "      545    0.001    0.000    0.001    0.000 linalg.py:199(_assert_stacked_square)\n",
      "      267    0.007    0.000    0.012    0.000 linalg.py:2104(det)\n",
      "      545    0.000    0.000    0.000    0.000 linalg.py:472(_unary_dispatcher)\n",
      "      278    0.010    0.000    0.015    0.000 linalg.py:476(inv)\n",
      "      545    0.000    0.000    0.000    0.000 multiarray.py:1054(copyto)\n",
      "      556    0.000    0.000    0.000    0.000 multiarray.py:143(concatenate)\n",
      "      278    0.000    0.000    0.000    0.000 multiarray.py:644(result_type)\n",
      "      278    0.000    0.000    0.000    0.000 multiarray.py:75(empty_like)\n",
      "        1    0.000    0.000    0.001    0.001 npyio.py:284(load)\n",
      "      267    0.001    0.000    0.003    0.000 numeric.py:148(ones)\n",
      "      278    0.000    0.000    0.000    0.000 numeric.py:213(_ones_like_dispatcher)\n",
      "      278    0.001    0.000    0.006    0.000 numeric.py:217(ones_like)\n",
      "      278    0.000    0.000    0.000    0.000 numeric.py:2260(_isclose_dispatcher)\n",
      "      278    0.004    0.000    0.035    0.000 numeric.py:2264(isclose)\n",
      "      278    0.006    0.000    0.015    0.000 numeric.py:2344(within_tol)\n",
      "      267    0.000    0.000    0.000    0.000 numeric.py:420(_count_nonzero_dispatcher)\n",
      "      267    0.002    0.000    0.009    0.000 numeric.py:424(count_nonzero)\n",
      "      278    0.000    0.000    0.001    0.000 numerictypes.py:231(obj2sctype)\n",
      "     1090    0.001    0.000    0.002    0.000 numerictypes.py:285(issubclass_)\n",
      "      545    0.001    0.000    0.003    0.000 numerictypes.py:359(issubdtype)\n",
      "        1    0.000    0.000    0.000    0.000 os.py:198(makedirs)\n",
      "        1    0.000    0.000    0.000    0.000 os.py:613(get_exec_path)\n",
      "        3    0.000    0.000    0.000    0.000 os.py:670(__getitem__)\n",
      "        3    0.000    0.000    0.000    0.000 os.py:748(encode)\n",
      "        1    0.000    0.000    0.000    0.000 os.py:752(decode)\n",
      "       60    0.000    0.000    0.000    0.000 os.py:800(fsencode)\n",
      "        1    0.000    0.000    0.000    0.000 posixpath.py:100(split)\n",
      "        1    0.000    0.000    0.000    0.000 posixpath.py:117(splitext)\n",
      "        7    0.000    0.000    0.000    0.000 posixpath.py:150(dirname)\n",
      "      624    0.000    0.000    0.000    0.000 posixpath.py:41(_get_sep)\n",
      "      616    0.002    0.000    0.003    0.000 posixpath.py:71(join)\n",
      "        1    0.000    0.000    0.000    0.000 py3k.py:53(isfileobj)\n",
      "        8    0.000    0.000    0.000    0.000 random.py:250(_randbelow_with_getrandbits)\n",
      "        8    0.000    0.000    0.000    0.000 random.py:285(choice)\n",
      "       19    0.000    0.000    0.000    0.000 re.py:250(compile)\n",
      "       19    0.000    0.000    0.000    0.000 re.py:289(_compile)\n",
      "      278    0.000    0.000    0.000    0.000 shape_base.py:136(_atleast_3d_dispatcher)\n",
      "      278    0.004    0.000    0.005    0.000 shape_base.py:140(atleast_3d)\n",
      "      556    0.001    0.000    0.002    0.000 shape_base.py:208(_arrays_for_stack_dispatcher)\n",
      "      278    0.000    0.000    0.001    0.000 shape_base.py:219(_vhstack_dispatcher)\n",
      "      278    0.001    0.000    0.011    0.000 shape_base.py:223(vstack)\n",
      "      278    0.001    0.000    0.002    0.000 shape_base.py:659(_dstack_dispatcher)\n",
      "      278    0.002    0.000    0.108    0.000 shape_base.py:663(dstack)\n",
      "      278    0.000    0.000    0.000    0.000 shape_base.py:78(_atleast_2d_dispatcher)\n",
      "      278    0.004    0.000    0.005    0.000 shape_base.py:82(atleast_2d)\n",
      "        1    0.001    0.001    0.008    0.008 shutil.py:625(_rmtree_safe_fd)\n",
      "        1    0.000    0.000    0.008    0.008 shutil.py:682(rmtree)\n",
      "      841    0.038    0.000    0.038    0.000 socket.py:543(send)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:1038(__del__)\n",
      "      280    0.002    0.000    0.028    0.000 std.py:1041(__repr__)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:1044(_comparable)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:1048(__hash__)\n",
      "      279    0.007    0.000    0.288    0.001 std.py:1051(__iter__)\n",
      "        2    0.000    0.000    0.003    0.001 std.py:1213(close)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:1230(fp_write)\n",
      "      280    0.004    0.000    0.004    0.000 std.py:1364(format_dict)\n",
      "      280    0.002    0.000    0.277    0.001 std.py:1379(display)\n",
      "      280    0.001    0.000    0.001    0.000 std.py:146(__init__)\n",
      "      280    0.001    0.000    0.001    0.000 std.py:153(__format__)\n",
      "      559    0.001    0.000    0.004    0.000 std.py:226(format_interval)\n",
      "      556    0.001    0.000    0.001    0.000 std.py:267(ema)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:286(status_printer)\n",
      "      280    0.002    0.000    0.245    0.001 std.py:296(fp_write)\n",
      "      280    0.001    0.000    0.247    0.001 std.py:302(print_status)\n",
      "      280    0.009    0.000    0.023    0.000 std.py:309(format_meter)\n",
      "        1    0.000    0.000    0.001    0.001 std.py:502(__new__)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:524(_get_free_pos)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:527(<genexpr>)\n",
      "        1    0.000    0.000    0.001    0.001 std.py:531(_decr_instances)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:604(get_lock)\n",
      "        1    0.000    0.000    0.002    0.002 std.py:766(__init__)\n",
      "      283    0.001    0.000    0.002    0.000 std.py:88(acquire)\n",
      "      283    0.001    0.000    0.002    0.000 std.py:92(release)\n",
      "      283    0.001    0.000    0.003    0.000 std.py:96(__enter__)\n",
      "      283    0.000    0.000    0.002    0.000 std.py:99(__exit__)\n",
      "        5    0.000    0.000    0.000    0.000 subprocess.py:1052(poll)\n",
      "        3    0.000    0.000    0.000    0.000 subprocess.py:1078(wait)\n",
      "        3    0.001    0.000    0.001    0.000 subprocess.py:1101(_close_pipe_fds)\n",
      "        3    0.000    0.000    0.000    0.000 subprocess.py:1459(_get_handles)\n",
      "        3    0.002    0.001    0.175    0.058 subprocess.py:1552(_execute_child)\n",
      "       58    0.000    0.000    0.000    0.000 subprocess.py:1634(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 subprocess.py:1708(_handle_exitstatus)\n",
      "        8    0.000    0.000    0.000    0.000 subprocess.py:1726(_internal_poll)\n",
      "        2    0.000    0.000    0.000    0.000 subprocess.py:1761(_try_wait)\n",
      "        3    0.000    0.000    0.000    0.000 subprocess.py:1774(_wait)\n",
      "        1    0.000    0.000    0.000    0.000 subprocess.py:1929(send_signal)\n",
      "        1    0.000    0.000    0.000    0.000 subprocess.py:1935(terminate)\n",
      "        3    0.000    0.000    0.000    0.000 subprocess.py:241(_cleanup)\n",
      "        1    0.000    0.000    0.000    0.000 subprocess.py:430(__init__)\n",
      "        1    0.000    0.000    0.348    0.348 subprocess.py:452(run)\n",
      "        3    0.000    0.000    0.176    0.059 subprocess.py:736(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 subprocess.py:908(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 subprocess.py:911(__exit__)\n",
      "        3    0.000    0.000    0.000    0.000 subprocess.py:939(__del__)\n",
      "        1    0.000    0.000    0.000    0.000 subprocess.py:954(_get_devnull)\n",
      "        2    0.000    0.000    0.354    0.177 subprocess.py:984(communicate)\n",
      "        1    0.000    0.000    0.000    0.000 tempfile.py:105(_sanitize_params)\n",
      "        1    0.000    0.000    0.000    0.000 tempfile.py:133(rng)\n",
      "        1    0.000    0.000    0.000    0.000 tempfile.py:144(__next__)\n",
      "        1    0.000    0.000    0.000    0.000 tempfile.py:147(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 tempfile.py:224(_get_candidate_names)\n",
      "        1    0.000    0.000    0.000    0.000 tempfile.py:279(gettempdir)\n",
      "        1    0.000    0.000    0.000    0.000 tempfile.py:334(mkdtemp)\n",
      "        1    0.000    0.000    0.000    0.000 tempfile.py:84(_infer_return_type)\n",
      "     1122    0.001    0.000    0.003    0.000 threading.py:1017(_wait_for_tstate_lock)\n",
      "      560    0.000    0.000    0.000    0.000 threading.py:1047(ident)\n",
      "     1121    0.002    0.000    0.004    0.000 threading.py:1071(is_alive)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:1095(daemon)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1110(daemon)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1177(_make_invoke_excepthook)\n",
      "      283    0.001    0.000    0.001    0.000 threading.py:1306(current_thread)\n",
      "      282    0.003    0.000    0.003    0.000 threading.py:222(__init__)\n",
      "      282    0.000    0.000    0.000    0.000 threading.py:246(__enter__)\n",
      "      282    0.000    0.000    0.000    0.000 threading.py:249(__exit__)\n",
      "      272    0.000    0.000    0.000    0.000 threading.py:255(_release_save)\n",
      "      272    0.000    0.000    0.001    0.000 threading.py:258(_acquire_restore)\n",
      "      273    0.000    0.000    0.000    0.000 threading.py:261(_is_owned)\n",
      "      272    0.002    0.000    0.179    0.001 threading.py:270(wait)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:341(notify)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:364(notify_all)\n",
      "      282    0.001    0.000    0.003    0.000 threading.py:505(__init__)\n",
      "     1125    0.000    0.000    0.000    0.000 threading.py:513(is_set)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:519(set)\n",
      "      281    0.002    0.000    0.182    0.001 threading.py:540(wait)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:734(_newname)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:761(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:834(start)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:944(_stop)\n",
      "        1    0.000    0.000    0.001    0.001 threading.py:979(join)\n",
      "        1    0.000    0.000    0.000    0.000 tokenize.py:164(__init__)\n",
      "       19    0.000    0.000    0.000    0.000 tokenize.py:170(add_whitespace)\n",
      "        1    0.000    0.000    0.000    0.000 tokenize.py:183(untokenize)\n",
      "        1    0.000    0.000    0.000    0.000 tokenize.py:257(untokenize)\n",
      "       21    0.000    0.000    0.000    0.000 tokenize.py:429(_tokenize)\n",
      "        1    0.000    0.000    0.000    0.000 tokenize.py:612(generate_tokens)\n",
      "       19    0.000    0.000    0.000    0.000 tokenize.py:98(_compile)\n",
      "      534    0.004    0.000    0.006    0.000 twodim_base.py:156(eye)\n",
      "      267    0.000    0.000    0.000    0.000 twodim_base.py:225(_diag_dispatcher)\n",
      "      267    0.002    0.000    0.004    0.000 twodim_base.py:229(diag)\n",
      "       19    0.000    0.000    0.000    0.000 types.py:171(__get__)\n",
      "      280    0.000    0.000    0.000    0.000 utils.py:130(__init__)\n",
      "      280    0.000    0.000    0.000    0.000 utils.py:134(__format__)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:147(__eq__)\n",
      "      278    0.006    0.000    0.083    0.000 utils.py:1474(assert_allclose)\n",
      "      278    0.001    0.000    0.038    0.000 utils.py:1522(compare)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:184(_is_utf)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:198(_supports_unicode)\n",
      "      560    0.002    0.000    0.003    0.000 utils.py:205(_is_ascii)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:214(_environ_cols_wrapper)\n",
      "      278    0.001    0.000    0.001    0.000 utils.py:217(get_bound_method_class)\n",
      "      278    0.009    0.000    0.103    0.000 utils.py:224(safe_as_int)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:266(_environ_cols_linux)\n",
      "      278    0.001    0.000    0.459    0.002 utils.py:350(convert_to_float)\n",
      "      278    0.000    0.000    0.000    0.000 utils.py:382(_validate_interpolation_order)\n",
      "      278    0.007    0.000    0.075    0.000 utils.py:699(assert_array_compare)\n",
      "      556    0.001    0.000    0.001    0.000 utils.py:710(isnumber)\n",
      "      834    0.012    0.000    0.023    0.000 utils.py:716(func_assert_same_pos)\n",
      "      556    0.002    0.000    0.002    0.000 utils.py:770(<lambda>)\n",
      "      556    0.002    0.000    0.002    0.000 utils.py:773(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:934(safe_eval)\n",
      "        1    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\n",
      "        1    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\n",
      "        1    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\n",
      "       10    0.000    0.000    0.000    0.000 xmltodict.py:102(startElement)\n",
      "       92    0.000    0.000    0.000    0.000 xmltodict.py:109(<genexpr>)\n",
      "       10    0.000    0.000    0.000    0.000 xmltodict.py:117(endElement)\n",
      "       13    0.000    0.000    0.000    0.000 xmltodict.py:148(characters)\n",
      "       10    0.000    0.000    0.000    0.000 xmltodict.py:154(push_data)\n",
      "        1    0.000    0.000    0.001    0.001 xmltodict.py:176(parse)\n",
      "        1    0.000    0.000    0.000    0.000 xmltodict.py:52(__init__)\n",
      "      102    0.000    0.000    0.000    0.000 xmltodict.py:84(_build_name)\n",
      "       10    0.000    0.000    0.000    0.000 xmltodict.py:97(_attrs_to_dict)\n",
      "       21    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x5619cd6619a0}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "        1    0.440    0.440    0.440    0.440 {built-in method _dlib_pybind11.get_frontal_face_detector}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _locale.nl_langinfo}\n",
      "        3    0.061    0.020    0.061    0.020 {built-in method _posixsubprocess.fork_exec}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISDIR}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISREG}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _struct.calcsize}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _struct.unpack}\n",
      "      557    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "      283    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _thread.start_new_thread}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method _warnings.warn}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method atexit.register}\n",
      "     1105    0.001    0.000    0.001    0.000 {built-in method builtins.abs}\n",
      "      267    0.001    0.000    0.001    0.000 {built-in method builtins.any}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "     1398    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}\n",
      "        1    0.000    0.000   64.313   64.313 {built-in method builtins.exec}\n",
      "     2211    0.002    0.000    0.002    0.000 {built-in method builtins.getattr}\n",
      "     3622    0.003    0.000    0.003    0.000 {built-in method builtins.hasattr}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "    10953    0.004    0.000    0.004    0.000 {built-in method builtins.isinstance}\n",
      "     7575    0.003    0.000    0.003    0.000 {built-in method builtins.issubclass}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "     3154    0.001    0.000    0.001    0.000 {built-in method builtins.len}\n",
      "      547    0.001    0.000    0.001    0.000 {built-in method builtins.max}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "      279    0.000    0.000    0.001    0.000 {built-in method builtins.next}\n",
      "     5880    0.001    0.000    0.001    0.000 {built-in method builtins.ord}\n",
      "     2224    0.006    0.000    0.006    0.000 {built-in method builtins.round}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method fcntl.ioctl}\n",
      "        7    0.001    0.000    0.001    0.000 {built-in method io.open}\n",
      "    11557    0.929    0.000    0.929    0.000 {built-in method numpy.array}\n",
      "8253/4383    0.122    0.000    0.409    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "     1346    0.001    0.000    0.001    0.000 {built-in method numpy.core._multiarray_umath.normalize_axis_index}\n",
      "      268    0.001    0.000    0.001    0.000 {built-in method numpy.empty}\n",
      "      278    0.004    0.000    0.004    0.000 {built-in method numpy.frombuffer}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.fromfile}\n",
      "     1112    0.001    0.000    0.001    0.000 {built-in method numpy.geterrobj}\n",
      "      556    0.001    0.000    0.001    0.000 {built-in method numpy.seterrobj}\n",
      "     1079    0.007    0.000    0.007    0.000 {built-in method numpy.zeros}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method posix.WEXITSTATUS}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method posix.WIFEXITED}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method posix.WIFSIGNALED}\n",
      "       13    0.000    0.000    0.000    0.000 {built-in method posix.close}\n",
      "      686    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.fstat}\n",
      "      283    0.001    0.000    0.001    0.000 {built-in method posix.getpid}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.kill}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.lstat}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.mkdir}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.open}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method posix.pipe}\n",
      "        3    0.110    0.037    0.110    0.037 {built-in method posix.read}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.remove}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.rmdir}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.scandir}\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method posix.stat}\n",
      "      279    0.006    0.000    0.006    0.000 {built-in method posix.unlink}\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method posix.waitpid}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method pyexpat.ParserCreate}\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method sys.audit}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method sys.exc_info}\n",
      "        1    0.010    0.010    0.010    0.010 {built-in method time.sleep}\n",
      "      838    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "      278    0.249    0.001    0.249    0.001 {cvtColor}\n",
      "      278    0.199    0.001    0.199    0.001 {imwrite}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'Parse' of 'pyexpat.xmlparser' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'ParseFile' of 'pyexpat.xmlparser' objects}\n",
      "      812    0.000    0.000    0.000    0.000 {method '__array_prepare__' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__enter__' of '_io._IOBase' objects}\n",
      "      282    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "      282    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "      283    0.001    0.000    0.001    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
      "      283    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
      "     2214    0.177    0.000    0.177    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "      278    0.001    0.000    0.003    0.000 {method 'all' of 'numpy.generic' objects}\n",
      "     1112    0.002    0.000    0.009    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
      "     1676    0.001    0.000    0.001    0.000 {method 'append' of 'collections.deque' objects}\n",
      "     3140    0.001    0.000    0.001    0.000 {method 'append' of 'list' objects}\n",
      "      267    0.001    0.000    0.001    0.000 {method 'astype' of 'numpy.generic' objects}\n",
      "     2447    0.045    0.000    0.045    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}\n",
      "      278    0.001    0.000    0.094    0.000 {method 'clip' of 'numpy.ndarray' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'close' of '_io.BufferedReader' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'close' of '_io.BufferedWriter' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'count' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'decode' of 'bytes' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "       65    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
      "       57    0.000    0.000    0.000    0.000 {method 'endswith' of 'bytes' objects}\n",
      "      559    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "     2237    0.006    0.000    0.008    0.000 {method 'format' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'get' of 'cv2.VideoCapture' objects}\n",
      "     2159    0.001    0.000    0.001    0.000 {method 'get' of 'dict' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
      "      278    0.001    0.000    0.001    0.000 {method 'isOpened' of 'cv2.VideoCapture' objects}\n",
      "      279    0.000    0.000    0.000    0.000 {method 'is_dir' of 'posix.DirEntry' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'isidentifier' of 'str' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}\n",
      "      557    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'locked' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'lower' of 'bytes' objects}\n",
      "      269    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\n",
      "       19    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\n",
      "      545    0.002    0.000    0.249    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
      "      534    0.001    0.000    0.017    0.000 {method 'mean' of 'numpy.ndarray' objects}\n",
      "      278    0.001    0.000    0.251    0.001 {method 'min' of 'numpy.ndarray' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'pop' of 'collections.deque' objects}\n",
      "       20    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "      556    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}\n",
      "      278    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "      284    0.864    0.003    0.864    0.003 {method 'read' of '_io.BufferedReader' objects}\n",
      "      278    0.206    0.001    0.206    0.001 {method 'read' of 'cv2.VideoCapture' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'readline' of '_io.StringIO' objects}\n",
      "     4640    0.529    0.000    0.529    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "      283    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}\n",
      "      283    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}\n",
      "      277    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "        1    0.002    0.002    0.002    0.002 {method 'release' of 'cv2.VideoCapture' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'remove' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}\n",
      "      278    0.001    0.000    0.001    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'rfind' of 'bytes' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}\n",
      "      278    0.000    0.000    0.000    0.000 {method 'round' of 'numpy.ndarray' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'rstrip' of 'bytes' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'seek' of '_io.BufferedReader' objects}\n",
      "       19    0.000    0.000    0.000    0.000 {method 'span' of 're.Match' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
      "       59    0.000    0.000    0.000    0.000 {method 'startswith' of 'bytes' objects}\n",
      "      559    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'strip' of 'str' objects}\n",
      "      534    0.001    0.000    0.007    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
      "      278    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
      "      280    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "      267    0.001    0.000    0.021    0.000 {method 'var' of 'numpy.ndarray' objects}\n",
      "      282    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}\n",
      "      278    0.000    0.000    0.000    0.000 {method 'zfill' of 'str' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "import re\n",
    "cProfile.run(\"extract_roi.preprocess_video(compress_vid_path, '/' + mouth_roi_path, face_predictor_path, mean_face_path)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/home/harveyw/harveyw/iw/av_hubert_updated/av_hubert/av_hubert/data/video-orig/angel_clip.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    creation_time   : 2022-12-06T17:33:57.000000Z\n",
      "    com.android.version: 12\n",
      "    com.android.capture.fps: 60.000000\n",
      "  Duration: 00:00:10.01, start: 0.000000, bitrate: 28228 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709), 1920x1080, 27965 kb/s, 59.72 fps, 59.94 tbr, 90k tbn, 180k tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-06T17:33:57.000000Z\n",
      "      handler_name    : VideoHandle\n",
      "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 256 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-06T17:33:57.000000Z\n",
      "      handler_name    : SoundHandle\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> hevc (libx265))\n",
      "  Stream #0:1 -> #0:1 (aac (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "x265 [info]: HEVC encoder version 3.2.1+1-b5c86a64bbbe\n",
      "x265 [info]: build info [Linux][GCC 9.3.0][64 bit] 8bit+10bit+12bit\n",
      "x265 [info]: using cpu capabilities: MMX2 SSE2Fast LZCNT SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "x265 [info]: Main profile, Level-3 (Main tier)\n",
      "x265 [warning]: No thread pool allocated, --wpp disabled\n",
      "x265 [warning]: No thread pool allocated, --lookahead-slices disabled\n",
      "x265 [info]: Slices                              : 1\n",
      "x265 [info]: frame threads / pool features       : 3 / none\n",
      "x265 [info]: Coding QT: max CU size, min CU size : 64 / 8\n",
      "x265 [info]: Residual QT: max TU size, max depth : 32 / 1 inter / 1 intra\n",
      "x265 [info]: ME / range / subpel / merge         : hex / 57 / 2 / 3\n",
      "x265 [info]: Keyframe min / max / scenecut / bias: 25 / 250 / 40 / 5.00\n",
      "x265 [info]: Lookahead / bframes / badapt        : 20 / 4 / 2\n",
      "x265 [info]: b-pyramid / weightp / weightb       : 1 / 1 / 0\n",
      "x265 [info]: References / ref-limit  cu / depth  : 3 / off / on\n",
      "x265 [info]: AQ: mode / str / qg-size / cu-tree  : 2 / 1.0 / 32 / 1\n",
      "x265 [info]: Rate Control / qCompress            : CRF-28.0 / 0.60\n",
      "x265 [info]: tools: rd=3 psy-rd=2.00 early-skip rskip signhide tmvp b-intra\n",
      "x265 [info]: tools: strong-intra-smoothing deblock sao\n",
      "Output #0, mp4, to '/home/harveyw/harveyw/iw/av_hubert_updated/av_hubert/av_hubert/data/video-comp/angel_clip_mp4_compressed.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    com.android.capture.fps: 60.000000\n",
      "    com.android.version: 12\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0(eng): Video: hevc (libx265) (hev1 / 0x31766568), yuv420p, 850x480, q=2-31, 25 fps, 12800 tbn, 25 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-06T17:33:57.000000Z\n",
      "      handler_name    : VideoHandle\n",
      "      encoder         : Lavc58.54.100 libx265\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 69 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-06T17:33:57.000000Z\n",
      "      handler_name    : SoundHandle\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "frame=  252 fps= 25 q=-0.0 Lsize=     627kB time=00:00:09.99 bitrate= 514.1kbits/s dup=0 drop=346 speed=   1x    \n",
      "video:515kB audio:100kB subtitle:0kB other streams:0kB global headers:2kB muxing overhead: 1.794154%\n",
      "x265 [info]: frame I:      2, Avg QP:28.57  kb/s: 5533.00 \n",
      "x265 [info]: frame P:     57, Avg QP:27.84  kb/s: 1356.44 \n",
      "x265 [info]: frame B:    193, Avg QP:34.96  kb/s: 88.01   \n",
      "x265 [info]: Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "x265 [info]: consecutive B-frames: 5.1% 3.4% 10.2% 22.0% 59.3% \n",
      "\n",
      "encoded 252 frames in 9.91s (25.44 fps), 418.13 kb/s, Avg QP:33.30\n",
      "[aac @ 0x55c49ecb84c0] Qavg: 1525.495\n",
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/home/harveyw/harveyw/iw/av_hubert_updated/av_hubert/av_hubert/data/video-comp/angel_clip_mp4_compressed.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:10.08, start: 0.000000, bitrate: 509 kb/s\n",
      "    Stream #0:0(eng): Video: hevc (Main) (hev1 / 0x31766568), yuv420p(tv, progressive), 850x480, 418 kb/s, 25 fps, 25 tbr, 12800 tbn, 25 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandle\n",
      "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 82 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandle\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to '/home/harveyw/harveyw/iw/av_hubert_updated/av_hubert/av_hubert/data/audio/angel_clip_mp4_audio.wav':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    ISFT            : Lavf58.29.100\n",
      "    Stream #0:0(eng): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandle\n",
      "      encoder         : Lavc58.54.100 pcm_s16le\n",
      "size=     311kB time=00:00:09.99 bitrate= 255.3kbits/s speed= 584x    \n",
      "video:0kB audio:311kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.024466%\n"
     ]
    }
   ],
   "source": [
    "orig_vid_path = wd + f'/data/video-orig/{file_name}'\n",
    "\n",
    "updated_file_name = file_name.replace(\".\", \"_\")\n",
    "\n",
    "compress_vid_path = wd + f'/data/video-comp/{updated_file_name}_compressed.mp4'\n",
    "mouth_roi_path = wd[1:] + f'/data/video-roi/{updated_file_name}_roi.mp4'\n",
    "audio_path = wd + f'/data/audio/{updated_file_name}_audio.wav'\n",
    "\n",
    "# file_name = orig_vid_path[orig_vid_path.rfind('/') + 1:]\n",
    "\n",
    "if not exists('/' + mouth_roi_path):\n",
    "  command = f'ffmpeg -i {orig_vid_path} -vcodec libx265 -crf 28 -r 25 -vf scale=850:480 -ac 1 {compress_vid_path}'\n",
    "  subprocess.call(command, shell=True)\n",
    "\n",
    "  # EXTRACT ROI\n",
    "  face_predictor_path = f\"{wd}/data/misc/shape_predictor_68_face_landmarks.dat\"\n",
    "  mean_face_path = f\"{wd}/data/misc/20words_mean_face.npy\"\n",
    "  extract_roi.preprocess_video(compress_vid_path, '/' + mouth_roi_path, face_predictor_path, mean_face_path)\n",
    "  # extract_mouth.process_video(compress_vid_path, '/' + mouth_roi_path, face_predictor_path)\n",
    "\n",
    "  # EXTRACT AUDIO\n",
    "  command = f\"ffmpeg -i {compress_vid_path} -ar 16000 -ac 1 -f wav {audio_path}\"\n",
    "  subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_name': 'av_hubert_pretraining', 'data': '/tmp/tmpfqu0m_ec', 'labels': ['wrd'], 'label_dir': '/tmp/tmpfqu0m_ec', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['audio', 'video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/checkpoint/bshi/data/lrs3//lang/spm/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}\n",
      "self.cfg.noise_wav:  None\n",
      "min keep: None\n",
      "max keep: 1000\n",
      "manifest path: /tmp/tmpfqu0m_ec/test.tsv\n",
      "root:  /\n",
      "names: [('home/harveyw/harveyw/iw/av_hubert_updated/av_hubert/av_hubert/data/video-roi/angel_clip_mp4_roi.mp4', '/home/harveyw/harveyw/iw/av_hubert_updated/av_hubert/av_hubert/data/audio/angel_clip_mp4_audio.wav:test-0')]\n",
      "noise_fn:  None\n",
      "[AVHubertSeq2Seq(\n",
      "  (encoder): HubertEncoderWrapper(\n",
      "    (w2v_model): AVHubertModel(\n",
      "      (feature_extractor_audio): SubModel(\n",
      "        (proj): Linear(in_features=104, out_features=1024, bias=True)\n",
      "      )\n",
      "      (feature_extractor_video): SubModel(\n",
      "        (resnet): ResEncoder(\n",
      "          (frontend3D): Sequential(\n",
      "            (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)\n",
      "            (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): PReLU(num_parameters=64)\n",
      "            (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (trunk): ResNet(\n",
      "            (layer1): Sequential(\n",
      "              (0): BasicBlock(\n",
      "                (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (relu1): PReLU(num_parameters=64)\n",
      "                (relu2): PReLU(num_parameters=64)\n",
      "                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (1): BasicBlock(\n",
      "                (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (relu1): PReLU(num_parameters=64)\n",
      "                (relu2): PReLU(num_parameters=64)\n",
      "                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (layer2): Sequential(\n",
      "              (0): BasicBlock(\n",
      "                (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (relu1): PReLU(num_parameters=128)\n",
      "                (relu2): PReLU(num_parameters=128)\n",
      "                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (downsample): Sequential(\n",
      "                  (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (1): BasicBlock(\n",
      "                (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (relu1): PReLU(num_parameters=128)\n",
      "                (relu2): PReLU(num_parameters=128)\n",
      "                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (layer3): Sequential(\n",
      "              (0): BasicBlock(\n",
      "                (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (relu1): PReLU(num_parameters=256)\n",
      "                (relu2): PReLU(num_parameters=256)\n",
      "                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (downsample): Sequential(\n",
      "                  (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (1): BasicBlock(\n",
      "                (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (relu1): PReLU(num_parameters=256)\n",
      "                (relu2): PReLU(num_parameters=256)\n",
      "                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (layer4): Sequential(\n",
      "              (0): BasicBlock(\n",
      "                (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (relu1): PReLU(num_parameters=512)\n",
      "                (relu2): PReLU(num_parameters=512)\n",
      "                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (downsample): Sequential(\n",
      "                  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (1): BasicBlock(\n",
      "                (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (relu1): PReLU(num_parameters=512)\n",
      "                (relu2): PReLU(num_parameters=512)\n",
      "                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          )\n",
      "        )\n",
      "        (proj): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      )\n",
      "      (post_extract_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "      (dropout_input): Dropout(p=0.1, inplace=False)\n",
      "      (dropout_features): Dropout(p=0.1, inplace=False)\n",
      "      (encoder): TransformerEncoder(\n",
      "        (pos_conv): Sequential(\n",
      "          (0): Conv1d(1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
      "          (1): SamePad()\n",
      "          (2): GELU(approximate='none')\n",
      "        )\n",
      "        (layers): ModuleList(\n",
      "          (0): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (1): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (2): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (3): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (4): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (5): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (6): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (7): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (8): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (9): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (10): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (11): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (12): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (13): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (14): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (15): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (16): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (17): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (18): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (19): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (20): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (21): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (22): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (23): TransformerSentenceEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "      (final_proj): None\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embed_tokens): Embedding(1000, 1024, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (6): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (7): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (8): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")]\n",
      "mix name: ('home/harveyw/harveyw/iw/av_hubert_updated/av_hubert/av_hubert/data/video-roi/angel_clip_mp4_roi.mp4', '/home/harveyw/harveyw/iw/av_hubert_updated/av_hubert/av_hubert/data/audio/angel_clip_mp4_audio.wav:test-0')\n",
      "self.audio_root: /\n",
      "audio_name: home/harveyw/harveyw/iw/av_hubert_updated/av_hubert/av_hubert/data/video-roi/angel_clip_mp4_roi.mp4\n",
      "path: /home/harveyw/harveyw/iw/av_hubert_updated/av_hubert/av_hubert/data/video-roi/angel_clip_mp4_roi.mp4\n",
      "AUDIO MODALITY\n",
      "audio_fn: /home/harveyw/harveyw/iw/av_hubert_updated/av_hubert/av_hubert/data/audio/angel_clip_mp4_audio.wav\n",
      "sample_rate: 16000\n",
      "wav_data.shape: (159403,)\n",
      "so i walked into first today not expected to see joe sleeping at green space but now that i see him i feel it\n"
     ]
    }
   ],
   "source": [
    "user_dir = \"./\"\n",
    "newHypo = newPredict(mouth_roi_path, audio_path, user_dir, models, cfg, task)\n",
    "print(newHypo)\n",
    "\n",
    "with open(f'{wd}/data/transcriptions/{updated_file_name}.txt', 'w') as f:\n",
    "  f.write(f'{file_name} - Speech Transcription\\n')\n",
    "  f.write(newHypo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('avhubert')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 11:38:47) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fde25f2f53be29d56cbe75d31373e5a9cbe0e2ed290fb6f5ff3a78f4c56c116f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
